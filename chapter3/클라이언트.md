# 클라이언트

카프카 클러스터는 명령을 내리거나 데이터를 송수신하기 위해 카프카 클라이언트 라이브러리는 카프카 프로듀서, 컨슈머, 어드민 클라이언트를 제공하는 카프카 클라이언트를 사용하여 애플리케이션을 개발한다. 

## 프로듀서 API

프로듀서 애플리케이션은 카프카에 필요한 데이터를 선언하고 브로커의 특정 토픽의 파티션에 전송한다. 

- 프로듀서는 데이터를 전송할 때 리더 파티션을 가지고 있는 카프카 브로커와 직접 통신한다.
- 프로듀서는 데이터를 직렬화하여 카프카 브로커로 보내기 때문에 자바에서 선언 가능한 모든 형태를 브로커로 전송할 수 있다. (직렬화를 사용하면 프로듀서는 자바 기본형과 참조형뿐만 아니라 동영상, 이미지 같은 바이너리 데이터도 프로듀서를 통해 전송할 수 있다.)

## 프로듀서 중요 개념

프로듀서는 카프카 브로커로 데이터를 전송할 때 내부적으로 파티셔너, 배치 생성 단계를 거친다. 

- partitioner에서 레코드는 토픽의 어느 파티션으로 전송될 것인지 정해진다.
    - `*Producer API 에서는 UniformStickyPartitioner 와 RoundRobinPartitioner 2개 파티션 제공`(둘 다 메시지 키가 있을 때는 메시지 키의 해시값과 파티션을 매칭하여 데이터를 전송)*
    - *메시지 키가 없을 때 RoundRobinPartitioner는 ProducerRecord가 들어오는 대로 파티션을 순회하면서 전송하기 때문에 배치로 묶이는 빈도가 적다. UniformStickyPartitioner는 어큐뮬레이터에서 데이터가 배치로 모두 묶일 때까지 기다렸다가 배치로 묶인 데이터는 모두 동일한 파티션에 전송.*
    - `*카프카 클라이언트 라이브러릴 2.5.0 버전에서는 파티셔너를 지정하지 않은 경우, UniformStickyPartitioner 가 기본 설정*`
- partitioner에 의해 구분된 레코드는 데이터를 전송하기 전에 accumulator에 데이터를 버퍼로 쌓아놓고 발송한다. 버퍼로 쌓인 데이터는 배치로 묶어서 전송함으로써 카프카의 프로듀서 처리량을 향상시키는 데에 상당히 도움을 준다.
    - sender 스레드는 어큐뮬레이터에 쌓인 배치 데이터를 가져가 카프카 브로커로 전송한다.
- 카프카 프로듀서는 압축 옵션을 통해 브로커로 전송 시 압축 방식을 정할 수 있다.
    - gzip, snappy, lz4, zstd 지원.
    - 압축 시 네트워크 처리량에 이득을 볼 수 있지만 압축 또는 압축 해제 시에 CPU 또는 메모리 리소스를 사용하므로 사용환경에 따라 적절한 옵션을 사용해야한다.

## 프로듀서 주요 옵션

프로듀서 애플리케이션을 실행할 때 설정해야 하는 필수 옵션과 선택 옵션이 있다. 선택 옵션은 미지정 시 default 사용 값이 있으므로 파악해두는 게 좋다. 

### 필수 옵션

- bootstrap.servers: 프로듀서가 데이터를 전송할 대상 카프카 클러스터에 속한 브로커의 hostname:port 를 1개 이상 작성한다. 2개 이상 브로커 정보를 입력하여 일부 브로커에 이슈가 발생하더라도 접속하는데에 이슈가 없도록 설정 가능하다.
- key.serializer: 레코드의 메시지 키를 직렬화하는 클래스를 지정한다.
- value.serializer: 레코드의 메시지 값을 직렬화화는 클래스를 지정한다.

---

### 선택 옵션

- acks: 프로듀서가 전송한 데이터가 브로커들에 정상적으로 저장되었는지 전송 성공 여부를 확인하는데에 사용하는 옵션이다.

| value | 설명 |
| --- | --- |
| 0 default | 프로듀서가 전송한 즉시 브로커에 데이터 저장 여부와 상관 없이 성공으로 판단한다. |
| 1 | 리더 파티션에 데이터가 저장되면 전송 성공으로 판단한다. |
| -1 or all | min.insync.replicas 개수에 해당하는 리더 파티션과 팔로워 파티션에 데이터가 저장되면 성공하는 것으로 판단한다. |
- buffer.memory: 브로커로 전송할 데이터를 배치로 모으기 위해 설정할 버퍼 메모리양을 지정한다. 기본 값은 32MB이다.
- retries: 프로듀서가 브로커로부터 에러를 받고 난 뒤 재전송을 시도하는 횟수를 지정한다. 기본값은 2147483647이다.
- batch.size: 배치로 전송할 레코드 최대 용량을 지정한다. 너무 작게 설정하면 프로듀서가 브로커로 더 자주 보내기 때문에 네트워크 부담이 있고 너무 크게 설정하면 메모리를 더 많이 사용하게 되는 점을 주의해야한다. 기본값은 16384이다.
- linger.ms: 배치를 전송하기 전까지 기다리는 최소 시간이다. 기본값은 0이다.
- partitioner.class: 레코드를 파티션에 전송할때 적용하는 파티셔너 클래스를 지정한다. 기본값은 org.apache.kafka.clients.producer.internals.DefaultPartitioner이다.
- enable.idempotence: 멱등성 프로듀서로 동작할지 여부를 설정한다. 기본값은 false다.
- transactional.id: 프로듀서가 레코드를 전송할때 레코드를 트랜잭션 단위로 묶을지 여부를 설정한다. 프로듀서의 고유한 트랜잭션 아이디를 설정할 수 있다. 이 값을 설정하면 트랜잭션 프로듀서를 동작한다. 기본값은 null이다.

## 컨슈머 API

프로듀서가 전송한 데이터는 카프카 브로커에 적재된다. 컨슈머는 적재된 데이터를 사용하기위해 브로커로부터 데이터를 가져와서 필요한 처리를 한다.

## 컨슈머 중요 개념

토픽의 포티션으로부터 데이터를 가져가기 위해 컨슈머를 운영하는 방법은 크게 2가지가 있다.

1. 1개 이상의 컨슈머로 이루어진 컨슈머 그룹을 운영
2. 토픽의 특정 파티션마다 구독하는 컨슈머를 운영

컨슈머 그룹으로 운영하는 방법은 컨슈머를 각 컨슈머 그룹으로부터 격리된 환경에서 안전하게 운영할 수 있도록 도와주는 카프카의 독특한 방식. 컨슈머 그룹으로 묶인 컨슈머들은 토픽의 1개 이상 파티션들에 할당되어 데이터를 가져갈 수 있다. 

- 컨슈머 그룹으로 묶인 컨슈머가 토픽을 구독해서 데이터를 가져갈 때, 1개의 파티션은 최대 1개의 컨슈머에 할당 가능하다. 그리고 1개 컨슈머는 여러 개의 파티션에 할당될 수 있다. N(파티션):1(컨슈머), 따라서 컨슈머 그룹의 컨슈머 개수는 가져가고자 하는 토픽의 파티션 개수보다 같거나 작아야 한다. (컨슈머 수가 더 많은 경우, 초과분의 컨슈머는 유휴상태)
- 컨슈머 그룹은 다른 컨슈머 그룹과 격리되는 특징을 가지고 있다. 따라서 카프카 프로듀서가 보낸 데이터를 각기 다른 역할을 하는 컨슈머 그룹끼리 영향을 받지 않게 처리할 수 있다는 장점이 있다.
    
    ⇒ 책에서는 컨슈머 그룹의 격리성으로  기존에 크게 순서에 연관성이 없는 2가지 처리 작업을 2개 컨슈머 그룹을 사용하여 비동기적으로 처리하는 예시를 들었다. 중요한 것은 순서와 상관없이 2가지 작업이 그룹으로 분리되었기 때문에 한 쪽에서 장애가 난다고 하더라도 나머지 한 쪽은 영향을 받지 않는다는것이다.
    

## 컨슈머 그룹의 장애

컨슈머 그룹으로 이루어진 컨슈머들 중 일부 컨슈머에 장애가 발생하면, 장애가 발생한 컨슈머에 할당된 파티션은 다른 컨슈머에 소유권이 넘어간다. 이러한 과정을 rebalancing이라고 한다. 

리밸런싱은 크게 두 가지 상황에서 발생.

1. 첫 번째는 컨슈머가 추가되는 상황
2. 컨슈머가 제외되는 상황. 컨슈머 중 1개에 장애 발생 시 이를 해소하기 위해 해당 컨슈머를 그룹에서 제외하여 모든 파티션이 지속적으로 데이터를 처리할 수 있도록 한다.

리밸런싱은 유용하지만 자주 일어나서는 안된다. 파티션의 소유권을 컨슈머로 재할당하는 과정에서 해당 컨슈머 그룹의 컨슈머들이 토픽의 데이터를 읽을 수가 없다. 

- 그룹 조정자(group coordinator)는 리밸런싱을 발동시키는 역할을 하는데 컨슈머 그룹의 컨슈머가 추가되고 삭제될 때를 감지한다. 카프카 브로커 중 한 대가 그룹 조정자의 역할을 수행한다.

컨슈머는 카프카 브로커로부터 데이터를 어디까지 가져갔는지 commit을 통해 기록한다. 

- 특정 토픽의 파티션을 어떤 컨슈머 그룹이 몇 번째 가져갔는지 브로커 내부에서 사용되는 내부 토픽(__consumer_offsets)에 기록된다.

⇒ 컨슈머 동작 이슈 발생으로 __consumer_offsets 토픽에 어느 레코드까지 읽어갔는지 오프셋 커밋이 기록되지 못했다면 데이터 처리의 중복이 발생할 수 있다. 따라서 컨슈머 애플리케이션에서는 오프셋 커밋을 정상적으로 처리했는지 검증해야한다.

![image.png](%E1%84%8F%E1%85%B3%E1%86%AF%E1%84%85%E1%85%A1%E1%84%8B%E1%85%B5%E1%84%8B%E1%85%A5%E1%86%AB%E1%84%90%E1%85%B3%2013f89d9ea2c68028bd91c8ebc3e005bc/image.png)

오프셋 커밋은 컨슈머 애플리케이션에서 명시적, 비명시적으로 수행할 수 있다. 

- enable.auto.commit=true (기본 옵션, poll() 메서드가 수행될 때 일정 간격모다 오프셋을 커밋)
    
    ⇒ 일정 간격마다 자동으로 오프셋 커밋을 처리하는 것을 비명시적 오프셋 커밋이라고 한다.
    
    ⇒ [auto.commit.intervals.ms](http://auto.commit.intervals.ms) 와 함께 사용되며 해당 값 이상이 지났을 때 그 시점까지 읽은 레코드의 오프셋을 커밋.
    

비명시적 오프셋 커밋은 편리하지만 데이터 중복 또는 유실될 수 있는 가능성이 있다.

명시작으로 오프셋을 커밋하려면 poll() 메서드 호출 이후에 반환받은 데이터의 처리가 완료되고 commitSync() 메서드를 호출하면 된다. 

- commitSync() 는 poll() 메서드를 통해 반환된 레코드의 가장 마지막 오프셋을 기준으로 커밋을 수행한다. 동기메서드이며, 비동기 호출은 commitAsync()를 사용할 수 있다. 하지만 비동기 커밋은 커밋 요청이 실패했을 경우 현재 처리 중인 데이터의 순서를 보장하지 않으며 데이터의 중복 처리가 발생할 수 있다.

컨슈머는 poll() 메서드를 통해 레코드들을 반환받지만 poll() 메서드를 호출하는 시점에 클러스터에서 데이터를 가져오는 것은 아니다. 컨슈머 애플리케이션을 실행하게 되면 내부에서 Fetcher 인스턴스가 생성되어 poll() 메서드를 호출하기 전에 미리 레코드들을 내부 큐로 가져온다. 이후에 사용자가 명시적으로 poll() 메서드를 호출하면 컨슈머는 내부 큐에 있는 레코드들을 반환받아 처리를 수행한다. 

![image.png](%E1%84%8F%E1%85%B3%E1%86%AF%E1%84%85%E1%85%A1%E1%84%8B%E1%85%B5%E1%84%8B%E1%85%A5%E1%86%AB%E1%84%90%E1%85%B3%2013f89d9ea2c68028bd91c8ebc3e005bc/image%201.png)

## 컨슈머 주요 옵션

컨슈머 애플리케이션을 실행할 때 설정해야 하는 필수 옵션과 선택 옵션이 있다. 선택 옵션은 미지정 시 default 사용 값이 있으므로 파악해두는 게 좋다. 

### **필수 옵션**

- bootstrap.servers : 프로듀서가 데이터를 전송할 대상 카프카 클러스터에 속한 브로커의 호스트 이름:포트를 1개 이상 작성한다. 2개 이상 브로커 정보를 입력하여 일부 브로커에 이슈가 발생하더라도 접속하는데에 이슈가 없더록 설정 가능하다.
- key.deserializer : 레코드의 메세지 키를 역직렬화하는 클래스를 지정한다.
- value.deserializer : 레코드의 메세지 값을 역직렬화하는 클래스를 지정한다.

---

### **선택 옵션**

- group.id : 컨슈머 그룹 아이디를 지정한다. subscribe() 메서드로 토픽을 구독하여 사용할 때는 이 옵션을 필수로 넣어야 한다. ( 기본값 : null )
- auto.offset.reset : 컨슈머 그룹이 특정 파티션을 읽을 때 저장된 컨슈머 오프셋이 없는 경우 어느 오프셋부터 읽을지 선택하는 옵션이다. 이미 컨슈머 오프셋이 있다면 이 옵션값은 무시된다. ( 기본값 : latest )
    - latest : 설정하면 가장 높은(가장 최근에 넣은) 오프셋부터 읽기 시작한다.
    - earlist : 설정하면 가장 낮은(가장 오래전에 넣은) 오프셋부터 읽기 시작한다.
    - none : 설정하면 컨슈머 그룹이 커밋한 기록이 있는지 찾아본다. 만약 커밋 기록이 없으면 오류를 반환하고, 커밋 기록이 있다면 기존 커밋 기록 이후 오프셋부터 읽기 시작한다.
- enable.auto.commit : 자동 커밋으로 할지 수동 커밋으로 할지 선택하는 옵션이다. (기본값 : true )
- auto.commit.interval.ms : 자동 커밋일 경우 오프셋 커밋 간격을 지정한다. ( 기본값 : 5,000[5초] )
- max.poll.records.poll : poll() 메서드를 통해 반환되는 레코드 갯수를 지정한다. ( 기본값 : 500 )
- session.timeout.ms : 컨슈머가 브로커와 연결이 끊기는 최대 시간이다. ( 기본값 : 10,000[10초] )
    - 네트워크 지연이 자주 발생하지 않거나 크지 않다면 기본값으로 이용하거나 그보다 조금 더 작은 값으로 설정해서 운영해도 큰 무리가 없다.
- heartbeat.interval.ms : 하트비트를 전송하는 시간 간격이다. ( 기본값 : 3,000[3초] )
- max.poll.interval.ms : poll() 메서드를 호출하는 간격의 최대 시간. ( 기본값 : 300,000[5분] )
    - 설정된 간격을 넘어설 경우 데이터 처리에 문제가 있다고 판단하고 리밸런싱을 진행하게 된다.
- isolation.level : 트랜잭션 프로듀서가 레코드를 트랙잭션 단위로 보낼 경우 사용한다.